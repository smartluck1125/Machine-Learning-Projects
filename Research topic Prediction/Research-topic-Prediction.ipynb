{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OdBntg3UTJg3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train = pd.read_csv('/content/drive/My Drive/ml/train.csv')\n",
    "test = pd.read_csv('/content/drive/My Drive/ml/test.csv')\n",
    "subission_pd = pd.read_csv('/content/drive/My Drive/ml/sample_submission_UVKGLZE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "c8wedvYeT4nm",
    "outputId": "1a91f831-6556-49e3-dcba-e87c7567241e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (20972, 9)\n",
      "Test shape: (8989, 3)\n",
      "Sample shape: (8989, 7)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape:',train.shape)\n",
    "print('Test shape:',test.shape)\n",
    "print('Sample shape:',subission_pd.shape)\n",
    "\n",
    "l = ['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_8-A4zRtT8Ss",
    "outputId": "91bb890b-601a-42ef-cb0c-1e2aaafcba28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18874, 2) (2098, 2)\n",
      "(18874, 6) (2098, 6)\n"
     ]
    }
   ],
   "source": [
    "test = test.drop(['ID'],axis=1)\n",
    "\n",
    "X = train.loc[:,['TITLE','ABSTRACT']]\n",
    "y = train.loc[:,l]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "y_test.reset_index(drop=True,inplace=True)\n",
    "X_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "y1 = np.array(y_train)\n",
    "y2 = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ENRy0yNfUaCK"
   },
   "outputs": [],
   "source": [
    "#Removing Punctuations\n",
    "\n",
    "X_train.replace('[^a-zA-Z]',' ', regex=True, inplace=True)\n",
    "X_test.replace('[^a-zA-Z]',' ', regex=True, inplace=True)\n",
    "\n",
    "test.replace('[^a-zA-Z]',' ', regex=True, inplace=True)\n",
    "\n",
    "#Converting to lower case characters\n",
    "\n",
    "for index in X_train.columns:\n",
    "  X_train[index] = X_train[index].str.lower()\n",
    "\n",
    "for index in X_test.columns:\n",
    "  X_test[index] = X_test[index].str.lower()\n",
    "\n",
    "for index in test.columns:\n",
    "  test[index] = test[index].str.lower()\n",
    "\n",
    "#Removing one letter words\n",
    "\n",
    "X_train['ABSTRACT'] = X_train['ABSTRACT'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n",
    "X_test['ABSTRACT'] = X_test['ABSTRACT'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n",
    "\n",
    "test['ABSTRACT'] = test['ABSTRACT'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n",
    "\n",
    "#Removing multiple blank spaces\n",
    "\n",
    "X_train = X_train.replace('\\s+', ' ', regex=True)\n",
    "X_test = X_test.replace('\\s+', ' ', regex=True)\n",
    "\n",
    "test = test.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "VJD5hEUkUfNY",
    "outputId": "1b4eff7d-4a42-44a3-8e4e-ae4f2ef4a533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13275</th>\n",
       "      <td>clustering in hilbert space of a quantum optim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19273</th>\n",
       "      <td>graph heat mixture model learning  graph infer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6427</th>\n",
       "      <td>fast and unsupervised methods for multilingual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19168</th>\n",
       "      <td>natasha faster non convex stochastic optimizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14148</th>\n",
       "      <td>kustaanheimo stiefel transformation with an ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                combined\n",
       "13275  clustering in hilbert space of a quantum optim...\n",
       "19273  graph heat mixture model learning  graph infer...\n",
       "6427   fast and unsupervised methods for multilingual...\n",
       "19168  natasha faster non convex stochastic optimizat...\n",
       "14148  kustaanheimo stiefel transformation with an ar..."
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "# len(stop_words)\n",
    "# X_train['ABSTRACT'] = X_train['ABSTRACT'].apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "# X_test['ABSTRACT'] = X_test['ABSTRACT'].apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "\n",
    "# test['ABSTRACT'] = test['ABSTRACT'].apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "\n",
    "X_train['combined'] = X_train['TITLE']+' '+X_train['ABSTRACT']\n",
    "X_test['combined'] = X_test['TITLE']+' '+X_test['ABSTRACT']\n",
    "\n",
    "test['combined'] = test['TITLE']+' '+test['ABSTRACT']\n",
    "\n",
    "X_train = X_train.drop(['TITLE','ABSTRACT'],axis=1)\n",
    "X_test = X_test.drop(['TITLE','ABSTRACT'],axis=1)\n",
    "\n",
    "test = test.drop(['TITLE','ABSTRACT'],axis=1)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZpJCI5cYCap"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_lines = []\n",
    "for row in range(0,X.shape[0]):\n",
    "  X_lines.append(' '.join(str(x) for x in X.iloc[row,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aKsTUdeRUrMd"
   },
   "outputs": [],
   "source": [
    "train_lines = []\n",
    "for row in range(0,X_train.shape[0]):\n",
    "  train_lines.append(' '.join(str(x) for x in X_train.iloc[row,:]))\n",
    "\n",
    "test_lines = []\n",
    "for row in range(0,X_test.shape[0]):\n",
    "  test_lines.append(' '.join(str(x) for x in X_test.iloc[row,:]))\n",
    "\n",
    "predtest_lines = []\n",
    "for row in range(0,test.shape[0]):\n",
    "  predtest_lines.append(' '.join(str(x) for x in test.iloc[row,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jGDABzRWZlOi",
    "outputId": "a9321f83-b977-43e7-9d7b-243bfeeaa754"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18874"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O05zD3CTUu_x"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvector = CountVectorizer(ngram_range=(1,2))\n",
    "X_train_cv = countvector.fit_transform(train_lines)\n",
    "X_test_cv = countvector.transform(test_lines)\n",
    "\n",
    "test_cv = countvector.transform(predtest_lines)\n",
    "\n",
    "#Using TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "tfidfvector = TfidfTransformer()\n",
    "X_train_tf = tfidfvector.fit_transform(X_train_cv)\n",
    "X_test_tf = tfidfvector.fit_transform(X_test_cv)\n",
    "\n",
    "test_tf = tfidfvector.fit_transform(test_cv)\n",
    "\n",
    "X_cv = countvector.transform(X_lines)\n",
    "\n",
    "X_tf = tfidfvector.fit_transform(X_cv) #x_tf,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "CcnLYLSQV3wk",
    "outputId": "eec93633-b54c-4efb-9403-19467293f4c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LinearSVC(C=0.5, class_weight='balanced',\n",
       "                                          dual=True, fit_intercept=True,\n",
       "                                          intercept_scaling=1,\n",
       "                                          loss='squared_hinge', max_iter=1000,\n",
       "                                          multi_class='ovr', penalty='l2',\n",
       "                                          random_state=42, tol=0.0001,\n",
       "                                          verbose=0),\n",
       "                      n_jobs=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "model = LinearSVC(C=0.5, class_weight='balanced', random_state=42)\n",
    "models = MultiOutputClassifier(model)\n",
    "\n",
    "models.fit(X_train_tf, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "MITfjxaeWGNf",
    "outputId": "b5b6e7e6-ac08-43ba-ced2-d19bd292fe39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = models.predict(X_test_tf)\n",
    "preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "f09g5ZevWI6e",
    "outputId": "a1410f03-caed-44f3-dd73-b19e1592f054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.85       853\n",
      "           1       0.88      0.89      0.88       623\n",
      "           2       0.84      0.84      0.84       580\n",
      "           3       0.72      0.86      0.78       516\n",
      "           4       0.53      0.40      0.46        58\n",
      "           5       0.86      0.69      0.77        26\n",
      "\n",
      "   micro avg       0.81      0.86      0.83      2656\n",
      "   macro avg       0.77      0.76      0.76      2656\n",
      "weighted avg       0.81      0.86      0.83      2656\n",
      " samples avg       0.84      0.89      0.84      2656\n",
      "\n",
      "0.6611058150619638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "#print(confusion_matrix(y2,preds))\n",
    "print(classification_report(y2,preds))\n",
    "print(accuracy_score(y2,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlszaq_ujFje"
   },
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     print(str(y2[i])+str(preds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LgQTqGrhjI7w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "mi9nVKeqWK-p",
    "outputId": "c27fb35b-0f4a-410e-ecdf-1b1b0aae4dae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predssv = models.predict(test_tf)\n",
    "predssv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "EBUnVCwlWPOZ",
    "outputId": "e99d8905-3d96-4471-8c2e-a43e2d4eef76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20974</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20977</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Computer Science  ...  Quantitative Biology  Quantitative Finance\n",
       "0  20973                 0  ...                     0                     0\n",
       "1  20974                 0  ...                     0                     0\n",
       "2  20975                 1  ...                     0                     0\n",
       "3  20976                 0  ...                     0                     0\n",
       "4  20977                 1  ...                     0                     0\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/content/drive/My Drive/ml/test.csv')\n",
    "\n",
    "submit = pd.DataFrame({'ID': test.ID, 'Computer Science': predssv[:,0],'Physics':predssv[:,1],\n",
    "                       'Mathematics':predssv[:,2],'Statistics':predssv[:,3],'Quantitative Biology':predssv[:,4],\n",
    "                       'Quantitative Finance':predssv[:,5]})\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybS28j2AWbio"
   },
   "outputs": [],
   "source": [
    "submit.to_csv('submission2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMhmjaEvacjvO1SJCWFndxi",
   "collapsed_sections": [],
   "mount_file_id": "1-RAfjiGOy2brJkcnEiA6loSQDSn5oPQ1",
   "name": "independenceday_challange",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
